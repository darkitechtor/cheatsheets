{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Web_scraping.ipynb","provenance":[],"authorship_tag":"ABX9TyNtyMmGIc9pVVETFuOjVeSV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x-j6UaKCICSS"},"source":["Scrapy Crawler"]},{"cell_type":"code","metadata":{"id":"rOfPPAK6HtpM"},"source":["'''\r\n","# импортируем библиотеки \r\n","import scrapy\r\n","from scrapy.crawler import CrawlerProcess\r\n","\r\n","# создаем парсер (хоть как-то работает)\r\n","class Trade_Spider(scrapy.Spider):\r\n","  name = 'trade_spider'\r\n","\r\n","  def start_requests(self):\r\n","    urls = ['https://cars.volga-rast.ru']\r\n","    for url in urls:\r\n","      yield scrapy.Request(url = url, callback = self.parse)\r\n","      \r\n","  def parse(self, response):\r\n","    # сохраним страницу\r\n","    html_file = 'main_page.html'\r\n","    with open(html_file,'wb') as fout:\r\n","      fout.write(response.body)\r\n","\r\n","# создаем парсер (вообще не работает)\r\n","class Trade_Spider(scrapy.Spider):\r\n","  name = 'trade_spider'\r\n","\r\n","  def start_requests(self):\r\n","    urls = ['https://cars.volga-rast.ru']\r\n","    for url in urls:\r\n","      yield scrapy.Request(url = url, callback = self.parse)\r\n","      \r\n","  def parse(self, response):\r\n","    yield {\r\n","      'client': url,\r\n","      'GTM': response.css('script').re(r'https://www.googletagmanager.com/gtm.js'),\r\n","      'Metrica N': response.css('script').re(r'ym\\(\\d{5,10}'),\r\n","      'Metrica IDs': response.css('script').re(r'ym\\(\\d{5,10}'),\r\n","      'Web_visor': response.css('script').re(r'webvisor:true')\r\n","    }\r\n","\r\n","# запускаем парсер\r\n","process = CrawlerProcess()\r\n","process.crawl(Trade_Spider)\r\n","process.start()\r\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKYl4k2fI3YJ"},"source":["Request + BeautifulSoup"]},{"cell_type":"code","metadata":{"id":"idvb3Qp0I0BF"},"source":["'''\r\n","# импортируем библиотеки \r\n","import requests\r\n","from bs4 import BeautifulSoup\r\n","\r\n","# создаем парсер\r\n","r = requests.get(url)\r\n","soup = BeautifulSoup(r.text)\r\n","scripts = soup.find_all('script') # ищем script на странице\r\n","'''"],"execution_count":null,"outputs":[]}]}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"loyc0GmuzfPu"},"outputs":[],"source":["# декоратор, выводящий время выполнения запроса\n","@print_timing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6XS7kNz8wnG"},"outputs":[],"source":["# как оформить переменную внутри комментария (sql-запроса)\n","query = \"\"\"\n","SELECT title, rating FROM recommendations\n","INNER JOIN courses ON courses.course_id = recommendations.course_id\n","WHERE user_id = %(user_id)s AND rating > %(threshold)s\n","ORDER BY rating DESC\n","\"\"\"\n","# Add the threshold parameter\n","predictions_df = pd.read_sql(query, db_engine, params={\"user_id\":user_id, \"threshold\":threshold})"]},{"cell_type":"markdown","metadata":{"id":"UFMT12HI5dot"},"source":["Распределенные вычисления"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gX-bBpJQz6kL"},"outputs":[],"source":["# multiprocessing.Pool API (считаем средний возраст спортсменов по годам на 4-х нодах)\n","from multiprocessing import Pool\n","\n","def take_mean_age(year_and_group):\n","  year, group = year_and_group\n","  return pd.DataFrame({\"Age\":group[\"Age\"].mean()}, index=[year])\n","  \n","with Pool(4) as p:\n","  results = p.map(take_mean_age, athlete_events.groupby(\"Year\"))\n","\n","result_df = pd.concat(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nZCHRlV0BGT"},"outputs":[],"source":["# dask (считаем средний возраст спортсменов по годам на 4-х нодах)\n","import dask.dataframe as dd\n","# Set the number of pratitions\n","athlete_events_dask = dd.from_pandas(athlete_events, npartitions=4)\n","# Calculate the mean Age per Year\n","print(athlete_events_dask.groupby('Year').Age.mean().compute())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9Vy8P3n0CcT"},"outputs":[],"source":["# PySpark\n","print(athlete_events_spark.printSchema())\n","\n","print(athlete_events_spark.groupBy('Year').mean('Age').show())"]},{"cell_type":"markdown","metadata":{"id":"2qFCnJZUB-A-"},"source":["Extracting data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUVlT1LcCAfF"},"outputs":[],"source":["# Data on Web through API\n","import requests\n","\n","# Fetch the Hackernews post\n","resp = requests.get(\"https://hacker-news.firebaseio.com/v0/item/16222426.json\")\n","\n","# Print the response parsed as JSON\n","print(resp.json())\n","\n","# Assign the score of the test to post_score\n","post_score = resp.json()['score']\n","print(post_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfhjp3_UDlFr"},"outputs":[],"source":["# Data from Databases with SQL\n","import sqlalchemy\n","# Connect to the database using the connection URI\n","'''\n","формат uri: postgresql://[user[:password]@][host][:port][/database]\n","            sqlite:///data.db\n","'''\n","connection_uri = \"postgresql://repl:password@localhost:5432/pagila\" \n","db_engine = sqlalchemy.create_engine(connection_uri)\n","\n","# Function to extract table to a pandas DataFrame\n","def extract_table_to_pandas(tablename, db_engine):\n","    query = \"SELECT * FROM {}\".format(tablename)\n","    return pd.read_sql(query, db_engine)\n","\n","# Extract the film table into a pandas DataFrame\n","extract_table_to_pandas('film', db_engine)\n","\n","# Extract the customer table into a pandas DataFrame\n","extract_table_to_pandas('customer', db_engine)"]},{"cell_type":"markdown","metadata":{"id":"hhB9y1LgHEZM"},"source":["Transforming data with Pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDNa3XQGHHK8"},"outputs":[],"source":["customer_df # Pandas DataFrame with customer data\n","# Split email column into 2 columns on the '@' symbol\n","split_email = customer_df.email.str.split(\"@\", expand=True)\n","# At this point, split_email will have 2 columns, a first# one with everything before @, and a second one with# everything after @\n","# Create 2 new columns using the resulting DataFrame.\n","customer_df = customer_df.assign(\n","    username = split_email[0],\n","    domain = split_email[1],\n",")"]},{"cell_type":"markdown","metadata":{"id":"dN4OALP6KOh3"},"source":["Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Meb49PV4KQOj"},"outputs":[],"source":["# Write the pandas DataFrame to parquet\n","film_pdf.to_parquet('films_pdf.parquet')\n","\n","# Write the PySpark DataFrame to parquet\n","film_sdf.write.parquet('films_sdf.parquet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9WmxcROKUKc"},"outputs":[],"source":["import sqlalchemy\n","# Connect to the database using the connection URI\n","connection_uri = \"postgresql://repl:password@localhost:5432/dwh\"\n","db_engine_dwh = sqlalchemy.create_engine(connection_uri)\n","\n","# Transformation step, join with recommendations data\n","film_pdf_joined = film_pdf.join(recommendations)\n","\n","# Write to store.film\n","film_pdf_joined.to_sql(\"film\", db_engine_dwh, schema=\"store\", if_exists=\"replace\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOSKY+PuftCtVnJcTCTUC7O","name":"Data Engineering.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.0"},"vscode":{"interpreter":{"hash":"1682e5d06a6d97c1b1cf6bb4ae6cf16223e994936ddb1d53664597d7d46101fa"}}},"nbformat":4,"nbformat_minor":0}
